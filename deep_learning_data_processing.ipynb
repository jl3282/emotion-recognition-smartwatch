{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your datasets (adjust the paths if needed)\n",
    "X1 = np.load('deep_learning_data/mo_ew2_accdata_21_10_139-1336_x.npy')\n",
    "y1 = pd.read_csv('deep_learning_data/mo_ew2_accdata_21_10_139-1336_y.csv')\n",
    "\n",
    "X2 = np.load('deep_learning_data/mo_ew3_accdata_16_12_1419-1449_x.npy')\n",
    "y2 = pd.read_csv('deep_learning_data/mo_ew3_accdata_16_12_1419-1449_y.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1 shape: (1186, 24, 7)\n",
      "y1 unique: [-1.  0.  1.]\n",
      "y1 shape: (1185, 1)\n",
      "X2 shape: (1182, 24, 7)\n",
      "y2 unique: [-1.  0.  1.]\n",
      "y2 shape: (1181, 1)\n"
     ]
    }
   ],
   "source": [
    "# Check dataset info\n",
    "print(\"X1 shape:\", X1.shape)\n",
    "print(\"y1 unique:\", np.unique(y1))\n",
    "print(\"y1 shape:\", y1.shape)\n",
    "print(\"X2 shape:\", X2.shape)\n",
    "print(\"y2 unique:\", np.unique(y2))\n",
    "print(\"y2 shape:\", y2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 44 dataset pairs\n"
     ]
    }
   ],
   "source": [
    "# Get paths for all X and y files\n",
    "x_files = glob.glob('deep_learning_data/*_x.npy')\n",
    "y_files = glob.glob('deep_learning_data/*_y.csv')\n",
    "\n",
    "# Sort to ensure matching pairs\n",
    "x_files.sort()\n",
    "y_files.sort()\n",
    "\n",
    "print(f\"Found {len(x_files)} dataset pairs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(x_files) == len(y_files), \"Mismatch in number of X vs Y files!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53836, 24, 7)\n",
      "(53836,)\n"
     ]
    }
   ],
   "source": [
    "def load_data(x_path, y_path):\n",
    "    X = np.load(x_path)                     # shape (n_windows, 24, 7)\n",
    "    y = pd.read_csv(y_path).values.squeeze() # shape (n_labels,)\n",
    "    n = min(len(X), len(y))\n",
    "    return X[:n], y[:n]\n",
    "\n",
    "# Load & accumulate\n",
    "all_X, all_y = [], []\n",
    "for xf, yf in zip(x_files, y_files):\n",
    "    X, y = load_data(xf, yf)\n",
    "    all_X.append(X)\n",
    "    all_y.append(y)\n",
    "\n",
    "# Concatenate across sessions\n",
    "X_all = np.concatenate(all_X, axis=0)       # (total_windows, 24, 7)\n",
    "y_all = np.concatenate(all_y, axis=0)       # (total_windows,)\n",
    "\n",
    "print(X_all.shape)\n",
    "print(y_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of sessions: 44\n",
      "Final X shape: (53836, 24, 7)\n",
      "Final y shape: (53836,)\n",
      "Unique labels in y: [-1.  0.  1.]\n",
      "Label distribution: [17954 17943 17939]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total number of sessions: {len(x_files)}\")\n",
    "print(f\"Final X shape: {X_all.shape}\")\n",
    "print(f\"Final y shape: {y_all.shape}\")\n",
    "print(f\"Unique labels in y: {np.unique(y_all)}\")\n",
    "print(f\"Label distribution: {np.bincount(y_all.astype(int) + 1)}\")  # +1 to handle -1 labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train / Val / Test shapes:\n",
      "  X_train: (37684, 24, 7), y_train: (37684,)\n",
      "  X_val:   (8076, 24, 7),   y_val:   (8076,)\n",
      "  X_test:  (8076, 24, 7),  y_test:  (8076,)\n"
     ]
    }
   ],
   "source": [
    "# Train/Val/Test split (70%/15%/15%) with stratification\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X_all, y_all, test_size=0.15, stratify=y_all, random_state=42\n",
    ")\n",
    "# Now split the 85% into 70/15 overall:\n",
    "val_ratio = 0.15 / 0.85\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=val_ratio, stratify=y_temp, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Train / Val / Test shapes:\\n\"\n",
    "      f\"  X_train: {X_train.shape}, y_train: {y_train.shape}\\n\"\n",
    "      f\"  X_val:   {X_val.shape},   y_val:   {y_val.shape}\\n\"\n",
    "      f\"  X_test:  {X_test.shape},  y_test:  {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Your data is now ready for modeling.\n"
     ]
    }
   ],
   "source": [
    "# Z-score normalization (fit on train only)\n",
    "scaler = StandardScaler()\n",
    "# flatten time & channels: (N, T, C) â†’ (N*T, C)\n",
    "train_flat = X_train.reshape(-1, X_train.shape[-1])\n",
    "scaler.fit(train_flat)\n",
    "\n",
    "def zscore_normalize(X):\n",
    "    flat = X.reshape(-1, X.shape[-1])\n",
    "    scaled = scaler.transform(flat)\n",
    "    return scaled.reshape(X.shape)\n",
    "\n",
    "X_train = zscore_normalize(X_train)\n",
    "X_val = zscore_normalize(X_val)  # Fixed missing parenthesis\n",
    "X_test = zscore_normalize(X_test)\n",
    "\n",
    "print(\"Done! Your data is now ready for modeling.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "moody",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
